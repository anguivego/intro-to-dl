{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week3_task2_fine_tuning_clean.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anguivego/intro-to-dl/blob/master/Introduction_to_deep_learning/week3/week3_task2_fine_tuning_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "i3nmuimqtcuC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning InceptionV3 for flowers classification\n",
        "\n",
        "In this task you will fine-tune InceptionV3 architecture for flowers classification task.\n",
        "\n",
        "InceptionV3 architecture (https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html):\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week3/images/inceptionv3.png?raw=1\" style=\"width:70%\">\n",
        "\n",
        "Flowers classification dataset (http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) consists of 102 flower categories commonly occurring in the United Kingdom. Each class contains between 40 and 258 images:\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week3/images/flowers.jpg?raw=1\" style=\"width:70%\">"
      ]
    },
    {
      "metadata": {
        "id": "UL8ykBDztcuF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import stuff"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "fpYMlgaltcuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import grading\n",
        "import download_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c9xgJ7xgtcuJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !!! remember to clear session/graph if you rebuild your graph to avoid out-of-memory errors !!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "XYUqIykRtcuM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download_utils.link_all_keras_resources()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:39.210959Z",
          "start_time": "2017-09-03T13:00:39.057800Z"
        },
        "scrolled": true,
        "id": "9Vnz15pdtcuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "import cv2  # for image processing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.io\n",
        "import os\n",
        "import tarfile\n",
        "import keras_utils\n",
        "from keras_utils import reset_tf_session "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VbdL8L14tcuQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fill in your Coursera token and email\n",
        "To successfully submit your answers to our grader, please fill in your Coursera submission token and email"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "q8NBlbbotcuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grader = grading.Grader(assignment_key=\"2v-uxpD7EeeMxQ6FWsz5LA\", \n",
        "                        all_parts=[\"wuwwC\", \"a4FK1\", \"qRsZ1\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "AQ38WBz1tcuU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = ### YOUR TOKEN HERE\n",
        "COURSERA_EMAIL = ### YOUR EMAIL HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wbq8Ar4ttcuW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ]
    },
    {
      "metadata": {
        "id": "IXzZtOJ5tcuX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dataset was downloaded for you, it takes 12 min and 400mb.\n",
        "Relevant links (just in case):\n",
        "- http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html\n",
        "- http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
        "- http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "SUFxfGK-tcuY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we downloaded them for you, just link them here\n",
        "download_utils.link_week_3_resources()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB5vRAD3tcub",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare images for model"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:39.214524Z",
          "start_time": "2017-09-03T13:00:39.212453Z"
        },
        "scrolled": false,
        "id": "uKp3EGlatcuc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we will crop and resize input images to IMG_SIZE x IMG_SIZE\n",
        "IMG_SIZE = 250"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-10T12:46:09.790818Z",
          "start_time": "2017-09-10T12:46:09.777771Z"
        },
        "scrolled": false,
        "id": "BhosRFyttcuf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_image_from_raw_bytes(raw_bytes):\n",
        "    img = cv2.imdecode(np.asarray(bytearray(raw_bytes), dtype=np.uint8), 1)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YOHLiob4tcuh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will take a center crop from each image like this:\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week3/images/center_crop.jpg?raw=1\" style=\"width:50%\">"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:39.393675Z",
          "start_time": "2017-09-03T13:00:39.302130Z"
        },
        "scrolled": false,
        "id": "AXpT1LLTtcui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_center_crop(img):\n",
        "    \"\"\"\n",
        "    Makes a square center crop of an img, which is a [h, w, 3] numpy array.\n",
        "    Returns [min(h, w), min(h, w), 3] output with same width and height.\n",
        "    For cropping use numpy slicing.\n",
        "    \"\"\"\n",
        "    \n",
        "    cropped_img = ### YOUR CODE HERE\n",
        "    \n",
        "    # checks for errors\n",
        "    h, w, c = img.shape\n",
        "    assert cropped_img.shape == (min(h, w), min(h, w), c), \"error in image_center_crop!\"\n",
        "    \n",
        "    return cropped_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:39.506473Z",
          "start_time": "2017-09-03T13:00:39.395470Z"
        },
        "scrolled": false,
        "id": "qBFhcu30tcuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_raw_bytes_for_model(raw_bytes, normalize_for_model=True):\n",
        "    img = decode_image_from_raw_bytes(raw_bytes)  # decode image raw bytes to matrix\n",
        "    img = image_center_crop(img)  # take squared center crop\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # resize for our model\n",
        "    if normalize_for_model:\n",
        "        img = img.astype(\"float32\")  # prepare for normalization\n",
        "        img = keras.applications.inception_v3.preprocess_input(img)  # normalize for model\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "1zd_YQkCtcum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reads bytes directly from tar by filename (slow, but ok for testing, takes ~6 sec)\n",
        "def read_raw_from_tar(tar_fn, fn):\n",
        "    with tarfile.open(tar_fn) as f:\n",
        "        m = f.getmember(fn)\n",
        "        return f.extractfile(m).read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:39.961301Z",
          "start_time": "2017-09-03T13:00:39.508004Z"
        },
        "scrolled": false,
        "id": "2R6qhooqtcup",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test cropping\n",
        "raw_bytes = read_raw_from_tar(\"102flowers.tgz\", \"jpg/image_00001.jpg\")\n",
        "\n",
        "img = decode_image_from_raw_bytes(raw_bytes)\n",
        "print(img.shape)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "img = prepare_raw_bytes_for_model(raw_bytes, normalize_for_model=False)\n",
        "print(img.shape)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "kX8pb6_Atcuq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## GRADED PART, DO NOT CHANGE!\n",
        "# Test image preparation for model\n",
        "prepared_img = prepare_raw_bytes_for_model(read_raw_from_tar(\"102flowers.tgz\", \"jpg/image_00001.jpg\"))\n",
        "grader.set_answer(\"qRsZ1\", list(prepared_img.shape) + [np.mean(prepared_img), np.std(prepared_img)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "LoJvY0hEtcuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# you can make submission with answers so far to check yourself at this stage\n",
        "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XvCuoGxmtcuy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare for training"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "MWqDs1hGtcuz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read all filenames and labels for them\n",
        "\n",
        "# read filenames firectly from tar\n",
        "def get_all_filenames(tar_fn):\n",
        "    with tarfile.open(tar_fn) as f:\n",
        "        return [m.name for m in f.getmembers() if m.isfile()]\n",
        "\n",
        "all_files = sorted(get_all_filenames(\"102flowers.tgz\"))  # list all files in tar sorted by name\n",
        "all_labels = scipy.io.loadmat('imagelabels.mat')['labels'][0] - 1  # read class labels (0, 1, 2, ...)\n",
        "# all_files and all_labels are aligned now\n",
        "N_CLASSES = len(np.unique(all_labels))\n",
        "print(N_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:40.185940Z",
          "start_time": "2017-09-03T13:00:40.175758Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "oOiHchq3tcu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split into train/test\n",
        "tr_files, te_files, tr_labels, te_labels = \\\n",
        "    train_test_split(all_files, all_labels, test_size=0.2, random_state=42, stratify=all_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "NMWoJyAktcu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# will yield raw image bytes from tar with corresponding label\n",
        "def raw_generator_with_label_from_tar(tar_fn, files, labels):\n",
        "    label_by_fn = dict(zip(files, labels))\n",
        "    with tarfile.open(tar_fn) as f:\n",
        "        while True:\n",
        "            m = f.next()\n",
        "            if m is None:\n",
        "                break\n",
        "            if m.name in label_by_fn:\n",
        "                yield f.extractfile(m).read(), label_by_fn[m.name]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:40.529088Z",
          "start_time": "2017-09-03T13:00:40.423114Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "Lh0N9V5Xtcu7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# batch generator\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def batch_generator(items, batch_size):\n",
        "    \"\"\"\n",
        "    Implement batch generator that yields items in batches of size batch_size.\n",
        "    There's no need to shuffle input items, just chop them into batches.\n",
        "    Remember about the last batch that can be smaller than batch_size!\n",
        "    Input: any iterable (list, generator, ...). You should do `for item in items: ...`\n",
        "        In case of generator you can pass through your items only once!\n",
        "    Output: In output yield each batch as a list of items.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "4laUR5nktcu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## GRADED PART, DO NOT CHANGE!\n",
        "# Test batch generator\n",
        "def _test_items_generator():\n",
        "    for i in range(10):\n",
        "        yield i\n",
        "\n",
        "grader.set_answer(\"a4FK1\", list(map(lambda x: len(x), batch_generator(_test_items_generator(), 3))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "y6yZDIf4tcvA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# you can make submission with answers so far to check yourself at this stage\n",
        "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:40.637615Z",
          "start_time": "2017-09-03T13:00:40.530642Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "UU3pndHQtcvC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_generator(files, labels):\n",
        "    while True:  # so that Keras can loop through this as long as it wants\n",
        "        for batch in batch_generator(raw_generator_with_label_from_tar(\n",
        "                \"102flowers.tgz\", files, labels), BATCH_SIZE):\n",
        "            # prepare batch images\n",
        "            batch_imgs = []\n",
        "            batch_targets = []\n",
        "            for raw, label in batch:\n",
        "                img = prepare_raw_bytes_for_model(raw)\n",
        "                batch_imgs.append(img)\n",
        "                batch_targets.append(label)\n",
        "            # stack images into 4D tensor [batch_size, img_size, img_size, 3]\n",
        "            batch_imgs = np.stack(batch_imgs, axis=0)\n",
        "            # convert targets into 2D tensor [batch_size, num_classes]\n",
        "            batch_targets = keras.utils.np_utils.to_categorical(batch_targets, N_CLASSES)\n",
        "            yield batch_imgs, batch_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:41.092659Z",
          "start_time": "2017-09-03T13:00:40.639132Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "DzWshfoBtcvD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test training generator\n",
        "for _ in train_generator(tr_files, tr_labels):\n",
        "    print(_[0].shape, _[1].shape)\n",
        "    plt.imshow(np.clip(_[0][0] / 2. + 0.5, 0, 1))\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AbLgQTMjtcvI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-10T13:16:35.109044Z",
          "start_time": "2017-09-10T13:16:35.105127Z"
        },
        "id": "aqx4eTDPtcvI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You cannot train such a huge architecture from scratch with such a small dataset.\n",
        "\n",
        "But using fine-tuning of last layers of pre-trained network you can get a pretty good classifier very quickly."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:41.097588Z",
          "start_time": "2017-09-03T13:00:41.094216Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "VFmNKhjVtcvJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to clear session if you start building graph from scratch!\n",
        "s = reset_tf_session()\n",
        "# don't call K.set_learning_phase() !!! (otherwise will enable dropout in train/test simultaneously)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:41.222209Z",
          "start_time": "2017-09-03T13:00:41.098974Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "Ors2RA6CtcvM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inception(use_imagenet=True):\n",
        "    # load pre-trained model graph, don't add final layer\n",
        "    model = keras.applications.InceptionV3(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                                          weights='imagenet' if use_imagenet else None)\n",
        "    # add global pooling just like in InceptionV3\n",
        "    new_output = keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "    # add new dense layer for our labels\n",
        "    new_output = keras.layers.Dense(N_CLASSES, activation='softmax')(new_output)\n",
        "    model = keras.engine.training.Model(model.inputs, new_output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:45.150429Z",
          "start_time": "2017-09-03T13:00:41.223777Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "hOtRlpAltcvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = inception()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:45.252883Z",
          "start_time": "2017-09-03T13:00:45.152062Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "LEVI8uCetcvR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:45.273005Z",
          "start_time": "2017-09-03T13:00:45.254250Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "QJW8tWsAtcvT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# how many layers our model has\n",
        "print(len(model.layers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:45.370171Z",
          "start_time": "2017-09-03T13:00:45.274354Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "_9hInPtltcvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set all layers trainable by default\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "    if isinstance(layer, keras.layers.BatchNormalization):\n",
        "        # we do aggressive exponential smoothing of batch norm\n",
        "        # parameters to faster adjust to our new dataset\n",
        "        layer.momentum = 0.9\n",
        "    \n",
        "# fix deep layers (fine-tuning only last 50)\n",
        "for layer in model.layers[:-50]:\n",
        "    # fix all but batch norm layers, because we neeed to update moving averages for a new dataset!\n",
        "    if not isinstance(layer, keras.layers.BatchNormalization):\n",
        "        layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T13:00:45.494833Z",
          "start_time": "2017-09-03T13:00:45.371512Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "tHFnXdIFtcvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compile new model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',  # we train 102-way classification\n",
        "    optimizer=keras.optimizers.adamax(lr=1e-2),  # we can take big lr here because we fixed first layers\n",
        "    metrics=['accuracy']  # report accuracy during training\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3BUJUXKgtcva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we will save model checkpoints to continue training in case of kernel death\n",
        "model_filename = 'flowers.{0:03d}.hdf5'\n",
        "last_finished_epoch = None\n",
        "\n",
        "#### uncomment below to continue training from model checkpoint\n",
        "#### fill `last_finished_epoch` with your latest finished epoch\n",
        "# from keras.models import load_model\n",
        "# s = reset_tf_session()\n",
        "# last_finished_epoch = 10\n",
        "# model = load_model(model_filename.format(last_finished_epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OE9f4kIItcvd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training takes **2 hours**. You're aiming for ~0.93 validation accuracy."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T14:23:36.792701Z",
          "start_time": "2017-09-03T13:00:45.496194Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "5O61E5Qxtcvf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fine tune for 2 epochs (full passes through all training data)\n",
        "# we make 2*8 epochs, where epoch is 1/8 of our training data to see progress more often\n",
        "model.fit_generator(\n",
        "    train_generator(tr_files, tr_labels), \n",
        "    steps_per_epoch=len(tr_files) // BATCH_SIZE // 8,\n",
        "    epochs=2 * 8,\n",
        "    validation_data=train_generator(te_files, te_labels), \n",
        "    validation_steps=len(te_files) // BATCH_SIZE // 4,\n",
        "    callbacks=[keras_utils.TqdmProgressCallback(), \n",
        "               keras_utils.ModelSaveCallback(model_filename)],\n",
        "    verbose=0,\n",
        "    initial_epoch=last_finished_epoch or 0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "yX1zq67Ztcvi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## GRADED PART, DO NOT CHANGE!\n",
        "# Accuracy on validation set\n",
        "test_accuracy = model.evaluate_generator(\n",
        "    train_generator(te_files, te_labels), \n",
        "    len(te_files) // BATCH_SIZE // 2\n",
        ")[1]\n",
        "grader.set_answer(\"wuwwC\", test_accuracy)\n",
        "print(test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "WOOnMX7Qtcvk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# you can make submission with answers so far to check yourself at this stage\n",
        "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0W3rYXEFtcvm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That's it! Congratulations!\n",
        "\n",
        "What you've done:\n",
        "- prepared images for the model\n",
        "- implemented your own batch generator\n",
        "- fine-tuned the pre-trained model"
      ]
    }
  ]
}